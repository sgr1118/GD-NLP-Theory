{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNaFQ1R88qimFPARUU4h4pg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/GD-NLP-Theory/blob/main/GD8_Translate_with_Seq2seq(221008).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-1. Seq2seq 기반 번역기 만들기\n",
        "\n",
        "이전 시간에 seq2seq 구조를 배웠다. 두 개의 RNN 모듈을 Encoder - Decoder 구조로 결합하여 사용하는 seq2seq는 혁신적이었다.\n",
        "\n",
        "이번 GD8에서는 seq2seq를 활용하여 직접 번역기를 만들어본다. 그리고 Attention 기법을 추가하여 성능을 높여보기로 한다.\n",
        "\n",
        "실습 데이터에는 영어-스페인어 말뭉치를 사용하고 프로젝트는 한국어-영어 말뭉치를 사용한다."
      ],
      "metadata": {
        "id": "H801d46tLqSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF3bfOJ7K_2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0040fa4-617d-4d6e-ae38-a2227682891e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 1s (17.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "# 사전 준비 - 한글 폰트 설치하기\n",
        "# 설치 후 런타임 다시 시작 필수\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-2. 데이터 전처리"
      ],
      "metadata": {
        "id": "BLG4HbJVQ0Gm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 데이터 준비하기"
      ],
      "metadata": {
        "id": "ghtPpPzpQ1d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxhukS7_QlqK",
        "outputId": "6566a9a1-9e89-473b-f214-1069979ce3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 다운로드하는 데에는 텐서플로우에서 제공하는 tf.keras.utils.get_file() 함수를 사용할 겁니다. get_file()함수는 URL로부터 데이터를 다운받고, 압축된 형식일 경우 해제까지 알아서 할 수 있는 똑똑한 함수랍니다! 아래 소스를 실행해 데이터를 다운로드받아주세요."
      ],
      "metadata": {
        "id": "DF-D45TOQ8fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip',\n",
        "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "metadata": {
        "id": "ZtNGkvEYQ-96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5fefc6-f98e-4bc5-a4d3-e05ff286437b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "2654208/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 형태 확인\n",
        "\n",
        "with open(path_to_file, \"r\") as f:\n",
        "    raw = f.read().splitlines()\n",
        "\n",
        "print(\"Data Size:\", len(raw))\n",
        "print(\"Example:\")\n",
        "\n",
        "for sen in raw[0:100][::20]: print(\">>\", sen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN8rjNdqRLzS",
        "outputId": "b9895136-fb9b-4515-a8cd-83cf1c71d713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Size: 118964\n",
            "Example:\n",
            ">> Go.\tVe.\n",
            ">> Wait.\tEsperen.\n",
            ">> Hug me.\tAbrázame.\n",
            ">> No way!\t¡Ni cagando!\n",
            ">> Call me.\tLlamame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 데이터 전처리 : 정제하기\n",
        "\n",
        "데이터는 \\t 기호를 기준으로 영어와 스페인어가 병렬 쌍을 이루고 있습니다. 고로 \\t 기호를 매개변수 split() 함수를 호출하면 손쉽게 소스 문장과 타겟 문장을 분리할 수 있다.\n",
        "\n",
        "추가로 위 예시에서 ¡같은 기호가 포함되어있어 이 같은 특수 문자는 불필요한 노이즈로 작용할 수 있기 때문에 정제 과정에서 삭제하도록 한다.\n",
        "\n",
        "사실 스페인에서는 역 물음표(¿)와 역 느낌표(¡)를 일반적으로 사용합니다. 문장이 물음표나 느낌표로 끝난다면 해당 문장 맨 앞에 역으로 된 기호를 붙여준다고 해요. 이해를 돕기 위해 이상한 기호 취급을 하였으니 양해를 바랍니다!\n"
      ],
      "metadata": {
        "id": "IcOE6SkTRPeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 코드\n",
        "\n",
        "def preprocessing_sentence(sentence, s_token=False, e_token=False):\n",
        "  sentence = sentence.lower().strip()\n",
        "\n",
        "  sentence = re.sub(r'([?.!,])', r' \\1', sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "  if s_token:\n",
        "    sentence = '<start> ' + sentence\n",
        "\n",
        "  if e_token:\n",
        "    sentence += ' <end>'\n",
        "\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "RO0Lk-7-leTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 과정에서 문장의 시작 문자 <start>, 종료 문자 <end> 를 붙여주게 됩니다. 이 작업은 Encoder에 들어갈 입력 문장의 전처리에는 굳이 필요하지 않지만, Decoder의 입력 문장과 라벨로 사용할 출력 문장에는 꼭 필요하게 됩니다. 이전 렉처 노드에서 살펴보았듯, Decoder는 첫 입력으로 사용할 시작 토큰과 문장생성 종료를 알리는 끝 토큰이 반드시 필요하기 때문입니다.\n",
        "\n",
        "원활한 학습을 위해 데이터는 상위 3만 개만 사용하도록 하겠습니다."
      ],
      "metadata": {
        "id": "_p5_csCU1liu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_corpus = []\n",
        "dec_corpus = []\n",
        "\n",
        "num_examples = 30000\n",
        "\n",
        "for pair in raw[:num_examples]:\n",
        "  eng, spa = pair.split('\\t')\n",
        "\n",
        "  enc_corpus.append(preprocessing_sentence(eng))\n",
        "  dec_corpus.append(preprocessing_sentence(spa, s_token=True, e_token=True))\n",
        "\n",
        "print(\"English:\", enc_corpus[100])   # go away !\n",
        "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SDyRKj815Mm",
        "outputId": "daa90e5c-02ac-471e-f4fa-12d42d2006b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: go away !\n",
            "Spanish: <start> salga de aqu ! <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 데이터 전처리 : 토큰화\n",
        "\n",
        "정제된 텍스트를 아래 tokenize() 함수를 사용해 토큰화하고 텐서로 변환하세요. 그리고 변환된 텐서를 80%의 훈련 데이터와 20%의 검증 데이터로 분리하세요! (Tokenizer의 단어 수는 자유롭게 진행하세요!)"
      ],
      "metadata": {
        "id": "Z57Q_kvu2kmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post')\n",
        "\n",
        "  return tensor, tokenizer"
      ],
      "metadata": {
        "id": "GpmldWFs2pkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화하기\n",
        "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
        "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
        "\n",
        "# 훈련 데이터와 검증 데이터로 분리하기\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_tensor, dec_tensor, test_size = 0.2)\n",
        "\n",
        "print(\"English Vocab Size:\", len(enc_tokenizer.index_word))\n",
        "print(\"Spanish Vocab Size:\", len(dec_tokenizer.index_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE6YP9vj6JFR",
        "outputId": "a0193dfe-20c7-4dc0-868e-426e231e0a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocab Size: 4934\n",
            "Spanish Vocab Size: 8895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-3. 모델 설계\n",
        "\n",
        "이제부터 아래 그림처럼 각각 1개의 GRU을 갖는 Encoder-Decoder 구조를 설계할 겁니다.\n",
        "\n",
        "![](https://d3s0tskafalll9.cloudfront.net/media/images/GN-4-P-2.max-800x600.jpg)\n",
        "<center>GRU 구조</center>\n",
        "\n",
        "Encoder는 모든 Time-Step의 Hidden State를 출력으로 갖고, Decoder는 Encoder의 출력과 Decoder의 t-1 Step의 Hidden State로 Attention을 취하여 tStep의 Hidden Stae를 만들어 냅니다.\n",
        "\n",
        "Decoder에서 tStep의 단어로 예측된 것을 실제 정답과 대조해 Loss를 구하고, 생선된 tStep의 Hidden State는 t+1 Step의 Hidden state를 만들기 위해 다시 Decoder에 전달됩니다.\n",
        "\n",
        "여기서 't=1일 때의 Hidden State는 어떻게 정의할 것인가?'가 궁금하실 수 있는데요, 일반적으로 Encoder의 Final State를 Hidden State로 사용합니다.\n",
        "\n",
        "Attention은 Bahdanau를 사용하고 위에서 작성한 코드를 그대로 가져다쓴다.\n",
        "\n",
        "[Bahdanau Attention 위키독스](https://wikidocs.net/73161)"
      ],
      "metadata": {
        "id": "adL0_KdB7Gv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.w_dec = tf.keras.layers.Dense(units)\n",
        "    self.w_enc = tf.keras.layers.Dense(units)\n",
        "    self.w_com = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self,h_enc, h_dec):\n",
        "    # h_enc shape: [batch x length x units]\n",
        "    # h_dec shape: [batch x units]\n",
        "\n",
        "    h_enc = self.w_enc(h_enc)\n",
        "    h_dec = tf.expand_dims(h_dec, 1)\n",
        "    h_dec = self.w_dec(h_dec)\n",
        "\n",
        "    score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
        "\n",
        "    attn = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vec = attn * h_enc\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1)\n",
        "\n",
        "    return context_vec, attn"
      ],
      "metadata": {
        "id": "fqW9UdUh_k_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 그림과 동일한 구조를 갖는 Encoder 클래스와 Decoder 클래스를 설계하기"
      ],
      "metadata": {
        "id": "ddAANMrsAtZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(enc_units, return_sequences=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    out = self.embedding(x)\n",
        "    out = self.gru(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "KenF-gU6BUxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(dec_units, return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    \n",
        "    self.attention = BahdanauAttention(self.dec_units)   # Attention 필수 사용!\n",
        "\n",
        "  def call(self, x, h_dec, enc_out):\n",
        "    context_vec, attn = self.attention(enc_out, h_dec)\n",
        "\n",
        "    out = self.embedding(x)\n",
        "    out = tf.concat([tf.expand_dims(context_vec, 1), out], axis = -1)\n",
        "\n",
        "    out, h_dec = self.gru(out)\n",
        "    out = tf.reshape(out, (-1, out.shape[2]))\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out, h_dec, attn"
      ],
      "metadata": {
        "id": "kmBivXl7DRwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#실행하여 결과 확인해보기\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
        "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
        "\n",
        "units = 1024\n",
        "embedding_dim = 512\n",
        "\n",
        "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
        "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
        "\n",
        "# sample input\n",
        "sequence_len = 30\n",
        "\n",
        "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
        "\n",
        "sample_output = encoder(sample_enc)\n",
        "\n",
        "print('Encoder Output : ', sample_output.shape)\n",
        "\n",
        "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
        "\n",
        "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                     sample_state, sample_output)\n",
        "\n",
        "print ('Decoder Output:', sample_logits.shape)\n",
        "print ('Decoder Hidden State:', h_dec.shape)\n",
        "print ('Attention:', attn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWfOVialcQZE",
        "outputId": "011b6a32-95e9-4aa3-a3a9-a3e9987acf34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output :  (64, 30, 1024)\n",
            "Decoder Output: (64, 8896)\n",
            "Decoder Hidden State: (64, 1024)\n",
            "Attention: (64, 30, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.random.uniform()에 대한 간단한 설명\n",
        "\n",
        "- tf.random.uniform()는 난수를 생성하기위해 사용된다.\n",
        "\n",
        "- tf.random.uniform()안에 shape, minval, maxval, dtype, seed, name가 들어갈 수 있다.\n",
        "\n",
        "자세한 설명은 tesorflow 공식 사이트 참고\n",
        "\n",
        "[tensorflow uniform](https://www.tensorflow.org/api_docs/python/tf/random/uniform)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V3CvLzYBgq_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-4. 훈련하기 (1) Optimizer & Loss\n",
        "\n",
        "지금까지는 fit() 함수로 간편하게 학습을 진행했지만, Encoder-Decoder 구조의 경우 입출력이 단순하지 않아 학습 과정을 직접 정의해줘야 합니다. 조금 불편하고 난감하게 다가올 수도 있지만 후에 더 멋진 연구를 하기 위한 발판이 되어 줄 테니 익숙해져 봅시다!\n",
        "\n",
        "낯선 함수들이 지나치게 많이 등장할 수 있으니, 이번 코스에선 직접 구현을 하기보단 구현체를 먼저 보고 이해하는 방향으로 공부하도록 합시다!\n"
      ],
      "metadata": {
        "id": "5MgORJ1-fhD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Optimizer & Loss\n",
        "\n",
        "Optimizer와 Loss에서 fit()을 사용하지 않는 이유는 Loss함수 때문이다. Encoder - Decoder 구조는 학습 과정이 일반적이지 않으므로 직접 Loss를 커스텀해서 사용해야한다.\n",
        "\n",
        "SparseCategoricalCrossentropy() 함수는 모델이 출력한 확률 분포와 (원-핫이 아닌) 정수 인덱스 답안을 비교해 Cross Entropy값을 구한다. \n",
        "\n",
        "CategoricalCrossentropy()라면 [ 0.1, 0.2, 0.7 ] 과 One-hot 인코딩된 라벨 [0, 0, 1] 을 비교하여 점수를 채점하겠지만, SparseCategoricalCrossentropy() 함수라면 [ 0.1, 0.2, 0.7 ] 과 정수 인덱스 답안 2 를 비교하여 점수를 채점하는 것이다.\n",
        "\n",
        "from_logits는 확률 분포가 Softmax를 거쳐서 들어오는지, 모델의 출력값 그대로 들어오는지를 결정한다. 아래에서 True로 줬으니 모델의 출력값을 그대로 전달하면된다.\n",
        "\n",
        "데이터를 한 번에 처리하기 위해 가장 긴 문장을 기준으로 패딩 과정을 거친다. tokenize() 함수 내부의 pad_sequences()가 바로 그 역할을 하였다.\n",
        "\n",
        "만약 모델에게 <PAD> 토큰이 패딩을 위한 토큰이라고 명시하지 않으면 모델은 데이터의 굉장히 많은 부분이 <PAD>로 이뤄져 있다고 생각하게 된다. 쉽게 말해 유난히 같은 답이 많은 객관식 시험이라고 생각한다.\n",
        "\n",
        "모델은 심지어 10000개의 정답이 넘게 있는 고난도의 문제를 풀고 있기에 패딩에 대한 처리를 해주지 않으면 <PAD>토큰만을 생성할 확률이 굉장히 높아진다.\n",
        "\n",
        "이것은 종종 발생하는 문제라서 기억해두고 향후 연구에서 활요하면 좋다. 그리고 이 문제를 방지하기 위해 mask가 사용된다.\n",
        "\n",
        "mask는 정답지에서 <PAD>토큰을 찾아내어 그 부분에 대한 Loss는 구하지 않도록 하는 역할을 한다. equal()함수에 정확히는 0이 아닌 <PAD>토큰의 인덱스를 전달하는 것이 맞지만 대부분의 경우는 0으로 패딩되기 때문에 편의상 0을 전달하여 처리하도록 한다.\n"
      ],
      "metadata": {
        "id": "clcEc8xIfzEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype = loss.dtype)\n",
        "  loss *= mask # *=는 왼쪽 변수에 오른쪽 값을 곱하고 그 결과를 왼쪽 변수에 할당한다.\n",
        "  # 예시로 a *= b는 a = a*b를 의미함.\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "Gc5ixf6Of0q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-5. 훈련하기 (2) train_step 구현하기\n",
        "\n",
        "train_step()의 학습 과정\n",
        "\n",
        "1. Encoder에 소스 문장을 전달해 context_vec인 enc_out을 생성\n",
        "\n",
        "2. t=0일 때, Decoder의 Hidden State는 Encoder의 Final State로 정의. h_dec = enc_out[:, -1]\n",
        "\n",
        "3. Decoder에 입력으로 전달한 <start>토큰 문장 생성\n",
        "\n",
        "4. <start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측. pred\n",
        "\n",
        "5. 예측된 단어와 정답 간의 Loss를 구한 후, t=1의 정답 단어를 다음 입력으로 사용 (예츠 단어 X)\n",
        "\n",
        "6. 반복"
      ],
      "metadata": {
        "id": "VHFMhrcdkol_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
        "  bsz = src.shape[0]\n",
        "  loss = 0 \n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_out = encoder(src)\n",
        "\n",
        "    # t=0일 때, Decoder의 Hidden State는 Encoder의 Final State로 정의.\n",
        "    h_dec = enc_out[:, -1] # 각 원소에서 맨 마지막 출력\n",
        "    \n",
        "    # Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
        "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "    # <start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측. \n",
        "    for t in range(1, tgt.shape[1]):\n",
        "      pred, h_dec,_ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "      loss += loss_function(tgt[:, t], pred) # 각 원소에서 t번째 출력하여 loss함수에 삽입\n",
        "      dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "metadata": {
        "id": "aIx-y4ITkqsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "@tf.function 데코레이터는 훈련 외적인 텐서플로우 연산을 GPU에서 동작하게 해 훈련을 가속할 수 있도록 도와줍니다. 첫 번째 Epoch이 다른 Epoch보다 약간의 시간이 더 걸리는 것은 데코레이터가 붙은 함수를 GPU에 등록하는 과정이 포함되어 있기 때문이죠! 실제로 위 예제에서 @tf.function 를 제거할 경우, Epoch당 1.5~2배 이상 더 많은 시간이 소요된답니다! 그러니 가능하다면 사용하는 쪽이 유리하겠죠? 아래는 @tf.function의 공식 문서입니다.\n",
        "\n",
        "[텐서플로 2.0의 tf.function과 오토그래프 (AutoGraph) | TensorFlow Core](https://www.tensorflow.org/guide/function?hl=ko)\n",
        "\n",
        "tf.GradientTape()는 학습하며 발생한 모든 연산을 기록하는 테이프입니다. 이것은 모델이 각 스텝의 최종 단계에서 미분값을 구하는 데에 사용됩니다. 이 또한 공식 문서를 첨부해드릴게요!\n",
        "\n",
        "[그래디언트 및 자동 미분 소개 | TensorFlow Core](https://www.tensorflow.org/guide/autodiff?hl=ko)"
      ],
      "metadata": {
        "id": "cw8_axcroTRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [:, -1] 예시\n",
        "a = [[0, 1, 2], [3, 4, 5]]\n",
        "a = np.array(a)\n",
        "a[:, -1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAp7YTMmmQsr",
        "outputId": "a9fe4125-b2fc-4442-c78d-988e13e038ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-6. 훈련하기 (3) 훈련 시작하기"
      ],
      "metadata": {
        "id": "6SkZZ488pnaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (batch, idx) in enumerate(t):\n",
        "    batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                            dec_train[idx:idx+BATCH_SIZE],\n",
        "                            encoder, decoder, optimizer, dec_tokenizer)\n",
        "    \n",
        "    total_loss += batch_loss\n",
        "\n",
        "    t.set_description_str('Epoch %2d' % (epoch + 1)) # # tqdm\n",
        "    t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1))) # tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH-OfqFUp8-Y",
        "outputId": "17ebdead-f825-4155-c034-ef30575e79ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [00:27<00:00, 13.78it/s, Loss 1.3431]\n",
            "Epoch  2: 100%|██████████| 375/375 [00:14<00:00, 25.17it/s, Loss 0.8680]\n",
            "Epoch  3: 100%|██████████| 375/375 [00:14<00:00, 25.62it/s, Loss 0.6082]\n",
            "Epoch  4: 100%|██████████| 375/375 [00:14<00:00, 25.53it/s, Loss 0.4358]\n",
            "Epoch  5: 100%|██████████| 375/375 [00:14<00:00, 25.48it/s, Loss 0.3261]\n",
            "Epoch  6: 100%|██████████| 375/375 [00:14<00:00, 25.54it/s, Loss 0.2526]\n",
            "Epoch  7: 100%|██████████| 375/375 [00:14<00:00, 25.62it/s, Loss 0.2055]\n",
            "Epoch  8: 100%|██████████| 375/375 [00:14<00:00, 25.50it/s, Loss 0.1769]\n",
            "Epoch  9: 100%|██████████| 375/375 [00:14<00:00, 25.67it/s, Loss 0.1535]\n",
            "Epoch 10: 100%|██████████| 375/375 [00:14<00:00, 25.54it/s, Loss 0.1392]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 EPOCHS = 10 만큼 반복하는 루프에 진입한 후, 각 배치의 시작 인덱스를 idx_list 배열에 저장한다. 그리고 모델이 학습을 원활하게 할 수 있도록 데이터를 섞어줘야 한다.\n",
        "\n",
        "이 과정은 인덱스를 섞어서 처리할 것이다. 순차적인 인덱스를 데이터로 불러오는 게 아닌 랜덤한 인덱스로 데이터를 불러오는 것은 데이터를 불러오는 것은 데이터를 섞는 것과 동일한 효과를 가져온다.\n",
        "\n",
        "그 후에 각 미니배치를 train_step() 함수에서 학습한다. train_step()은 학습에 필요한 것은 모두 가져가 Loss를 계산한 후 반환하는 함수였다."
      ],
      "metadata": {
        "id": "rGz1KBlKtO_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 실습하기\n",
        "\n",
        "Step 1에서 분리한 Validation Set을 사용하는 eval_step() 함수를 정의하세요! 그리고 train_step() 을 마친 후, 곧이어 eval_step() 을 진행하도록 소스를 수정하세요! 결과는 아래와 같은 형태가 되어야 합니다."
      ],
      "metadata": {
        "id": "pTyMshZ9uezu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eval_step() 정의하기\n",
        "# train_step() 이후 eval_step() 진행하도록 소스 수정하기\n",
        "\n",
        "# Define eval_step\n",
        "\n",
        "@tf.function\n",
        "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
        "  bsz = src.shape[0]\n",
        "  loss = 0 \n",
        "\n",
        "  enc_out = encoder(src)\n",
        "\n",
        "  # t=0일 때, Decoder의 Hidden State는 Encoder의 Final State로 정의.\n",
        "  h_dec = enc_out[:, -1] # 각 원소에서 맨 마지막 출력\n",
        "    \n",
        "  # Decoder에 입력으로 전달할 <start> 토큰 문장 생성\n",
        "  dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
        "\n",
        "  # <start> 문장과 enc_out, Hidden State를 기반으로 다음 단어(t=1)를 예측. \n",
        "  for t in range(1, tgt.shape[1]):\n",
        "    pred, h_dec,_ = decoder(dec_src, h_dec, enc_out)\n",
        "\n",
        "    loss += loss_function(tgt[:, t], pred) # 각 원소에서 t번째 출력하여 loss함수에 삽입\n",
        "    dec_src = tf.expand_dims(tgt[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(tgt.shape[1]))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "# Training Process\n",
        "\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (batch, idx) in enumerate(t):\n",
        "    batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                            dec_train[idx:idx+BATCH_SIZE],\n",
        "                            encoder, decoder, optimizer, dec_tokenizer)\n",
        "    \n",
        "    total_loss += batch_loss\n",
        "\n",
        "    t.set_description_str('Epoch %2d' % (epoch + 1)) # # tqdm\n",
        "    t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1))) # tqdm\n",
        "\n",
        "  test_loss = 0\n",
        "\n",
        "  idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
        "  random.shuffle(idx_list)\n",
        "  t = tqdm(idx_list)\n",
        "\n",
        "  for (test_batch, idx) in enumerate(t):\n",
        "    test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
        "                            dec_val[idx:idx+BATCH_SIZE],\n",
        "                            encoder, decoder, dec_tokenizer)\n",
        "    \n",
        "    test_loss += test_batch_loss\n",
        "\n",
        "    t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
        "    t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdpHe9hqupKy",
        "outputId": "3ee3db91-4c69-4734-f789-8159576908f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch  1: 100%|██████████| 375/375 [00:14<00:00, 25.37it/s, Loss 0.1190]\n",
            "Test Epoch  1: 100%|██████████| 94/94 [00:14<00:00,  6.62it/s, Test Loss 0.6948]\n",
            "Epoch  2: 100%|██████████| 375/375 [00:15<00:00, 24.47it/s, Loss 0.1164]\n",
            "Test Epoch  2: 100%|██████████| 94/94 [00:01<00:00, 50.67it/s, Test Loss 0.7029]\n",
            "Epoch  3: 100%|██████████| 375/375 [00:14<00:00, 25.73it/s, Loss 0.1113]\n",
            "Test Epoch  3: 100%|██████████| 94/94 [00:01<00:00, 53.90it/s, Test Loss 0.7109]\n",
            "Epoch  4: 100%|██████████| 375/375 [00:14<00:00, 25.71it/s, Loss 0.1048]\n",
            "Test Epoch  4: 100%|██████████| 94/94 [00:01<00:00, 53.77it/s, Test Loss 0.7212]\n",
            "Epoch  5: 100%|██████████| 375/375 [00:14<00:00, 25.55it/s, Loss 0.0982]\n",
            "Test Epoch  5: 100%|██████████| 94/94 [00:01<00:00, 53.73it/s, Test Loss 0.7224]\n",
            "Epoch  6: 100%|██████████| 375/375 [00:14<00:00, 25.56it/s, Loss 0.0935]\n",
            "Test Epoch  6: 100%|██████████| 94/94 [00:01<00:00, 53.73it/s, Test Loss 0.7293]\n",
            "Epoch  7: 100%|██████████| 375/375 [00:14<00:00, 25.62it/s, Loss 0.0906]\n",
            "Test Epoch  7: 100%|██████████| 94/94 [00:01<00:00, 53.73it/s, Test Loss 0.7345]\n",
            "Epoch  8: 100%|██████████| 375/375 [00:14<00:00, 25.62it/s, Loss 0.0911]\n",
            "Test Epoch  8: 100%|██████████| 94/94 [00:01<00:00, 53.75it/s, Test Loss 0.7478]\n",
            "Epoch  9: 100%|██████████| 375/375 [00:14<00:00, 25.54it/s, Loss 0.0918]\n",
            "Test Epoch  9: 100%|██████████| 94/94 [00:01<00:00, 53.69it/s, Test Loss 0.7511]\n",
            "Epoch 10: 100%|██████████| 375/375 [00:14<00:00, 25.62it/s, Loss 0.0870]\n",
            "Test Epoch 10: 100%|██████████| 94/94 [00:01<00:00, 53.77it/s, Test Loss 0.7636]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Map 시각화\n",
        "\n",
        "def evaluate(sentence, encoder, decoder):\n",
        "  attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
        "\n",
        "  sentence = preprocessing_sentence(sentence)\n",
        "  inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      inputs, maxlen = enc_train.shape[-1], padding='post')\n",
        "  \n",
        "  result = ''\n",
        "\n",
        "  enc_out = encoder(inputs)\n",
        "\n",
        "  dec_hidden = enc_out[:, -1]\n",
        "  dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(dec_train.shape[-1]):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
        "\n",
        "    result += dec_tokenizer.index_word[predicted_id] + ' '\n",
        "    \n",
        "    if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention\n",
        "\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  ax.matshow(attention, cmap = 'viridis')\n",
        "\n",
        "  fontdict = {'fontsize' : 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict = fontdict, rotation = 90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict = fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def translate(sentence, encoder, decdoer):\n",
        "  result, sentence, attention = evaluate(sentence, encoder, decdoer)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention = attention[:len(result.split()), :len(sentence.split())]\n",
        "  plot_attention(attention, sentence.split(), result.split(' '))\n",
        "\n",
        "translate(\"Can I have some coffee?\", encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "cP9J90ygxnSh",
        "outputId": "93a389f4-8e36-471a-8a28-de32b3ea120a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: can i have some coffee ?\n",
            "Predicted translation: me das un poco ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}